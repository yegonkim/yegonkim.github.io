---
title: Things I Don't Understand (Yet)
categories: Personal Thoughts
date: 2025-10-13
math: true
published: false
---

what I now understand:
the transformative impact that llms will have
theory of computation, algorithmic information theory
economics
the importance of empirical evidence


what I don't understand:

hard problem of consciousness, philosophy about mind, e.g. chinese room argument

machine learning theory, especially the ones like universal approximation theorem, or ones that predict the behavior of very small NNs in an exact fashion

game theory/economics

fast takeoff due to algorithmic improvements (aren't we bound significantly by compute available for experimentation?)

gradient descent as a godly optimizer (is it really that good? for finding low complexity programs) there was an arxiv problem, and recent TRM seems to use only gradient descent without any discerete variable sampling unlike language models ( i thought cots were better because of this sampling)

era of experience (i think rl will be more useful for using symbolic tools for world modeling. )


