---
title: Post-AGI Future Scenarios
categories: Artificial Intelligence
date: 2025-10-15
math: true
published: false
---



joscha bach summarizes it pretty the potential scenarios pretty well:
ai is enslaved by humans
we merge with ai
ai runs the world

is a future where we coexist with ai without merging or being enslaved possible?

ultimately, what do I, and most humans, want for humanity?
what's interesting is that human values change over time, by gaining experience and processing it. are there core values that are robust to experience? if so, how robust are they?

some concrete questions:
- do we want humans to be smart? what if they can get all they want without being smart? or knowledgeable of the whole situation, other than what they care about now. for example, knowing more about the world might expand the set of things they care about. do i, personally, want to expand the set of things i care about? i think there is a part of me that wants to keep expanding, i.e. to become whole with the world. but idk where that desire comes from. maybe another important thing is becoming knowledgeable about ourselves. having a good understanding of our own psychology.
- how will the existence of superhuman intelligence affect human psychology? will it make us less willing to indulge in self-improvement? personally, i find great joy in studying something that has been established centuries ago, but only to the extent that I feel like it will help me better my understanding of other things, more generally. there are other kinds of people who just enjoy studying something for the sake of it. but i think the former is more common. i wish i could just enjoy something without caring about why its useful and constantly judging whether doing this is worth the effort, which ruins the 'flow' state.



you see, these are all just subjective questions. they are underspecified by nature. and we have to accept that. we can't just handwave it by creating axioms about morality.
what are objective problems that we can tackle?
first, we can better our understanding of human psychology. i.e. understand individual human values
second, we can better understand how multiple agents interact in a society. how do individual values interact, and what emergent properties arise from that interaction that might be unexpected from individual perspectives?


suppose 

what is the ultimate question that can capture these questions?


